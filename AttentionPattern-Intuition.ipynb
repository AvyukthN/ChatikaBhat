{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ec26a45-3e05-44ae-b4be-639502998ffe",
   "metadata": {},
   "source": [
    "### Self Attention's Math Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "521d2676-4adb-47ee-868e-89bc46ffe4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n",
      "tensor([[[0.7667, 0.5314],\n",
      "         [0.9172, 0.2774],\n",
      "         [0.3465, 0.1333],\n",
      "         [0.7567, 0.7931],\n",
      "         [0.0519, 0.1533],\n",
      "         [0.1922, 0.9974],\n",
      "         [0.3706, 0.7383],\n",
      "         [0.5901, 0.1120]],\n",
      "\n",
      "        [[0.4926, 0.9296],\n",
      "         [0.4528, 0.9448],\n",
      "         [0.4835, 0.5699],\n",
      "         [0.6518, 0.5521],\n",
      "         [0.2763, 0.4441],\n",
      "         [0.1384, 0.8170],\n",
      "         [0.1880, 0.5782],\n",
      "         [0.1035, 0.7034]],\n",
      "\n",
      "        [[0.8070, 0.4398],\n",
      "         [0.9748, 0.6560],\n",
      "         [0.8835, 0.9323],\n",
      "         [0.0752, 0.4822],\n",
      "         [0.4767, 0.9107],\n",
      "         [0.2862, 0.2678],\n",
      "         [0.3134, 0.9763],\n",
      "         [0.2066, 0.9792]],\n",
      "\n",
      "        [[0.9492, 0.9015],\n",
      "         [0.0651, 0.0087],\n",
      "         [0.4753, 0.3830],\n",
      "         [0.4324, 0.9958],\n",
      "         [0.9457, 0.4595],\n",
      "         [0.8539, 0.7081],\n",
      "         [0.3116, 0.0152],\n",
      "         [0.8553, 0.4381]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "B,T,C = 4,8,2\n",
    "x = torch.rand(B, T, C)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac136af4-5ba6-478f-874e-23a8367cb804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7667, 0.5314],\n",
       "         [0.8419, 0.4044],\n",
       "         [0.6768, 0.3140],\n",
       "         [0.6968, 0.4338],\n",
       "         [0.5678, 0.3777],\n",
       "         [0.5052, 0.4810],\n",
       "         [0.4860, 0.5177],\n",
       "         [0.4990, 0.4670]],\n",
       "\n",
       "        [[0.4926, 0.9296],\n",
       "         [0.4727, 0.9372],\n",
       "         [0.4763, 0.8148],\n",
       "         [0.5202, 0.7491],\n",
       "         [0.4714, 0.6881],\n",
       "         [0.4159, 0.7096],\n",
       "         [0.3833, 0.6908],\n",
       "         [0.3484, 0.6924]],\n",
       "\n",
       "        [[0.8070, 0.4398],\n",
       "         [0.8909, 0.5479],\n",
       "         [0.8884, 0.6760],\n",
       "         [0.6851, 0.6276],\n",
       "         [0.6434, 0.6842],\n",
       "         [0.5839, 0.6148],\n",
       "         [0.5452, 0.6664],\n",
       "         [0.5029, 0.7055]],\n",
       "\n",
       "        [[0.9492, 0.9015],\n",
       "         [0.5072, 0.4551],\n",
       "         [0.4965, 0.4310],\n",
       "         [0.4805, 0.5722],\n",
       "         [0.5735, 0.5497],\n",
       "         [0.6203, 0.5761],\n",
       "         [0.5762, 0.4960],\n",
       "         [0.6111, 0.4887]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "for batch in range(B):\n",
    "    for token in range(T):\n",
    "        token_sub_sequence = x[batch, :token+1]\n",
    "        xbow[batch, token] = torch.mean(token_sub_sequence, 0)\n",
    "xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6b5be-091c-410d-a44a-1673f63dc3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df069020-c070-4210-bca6-142868ddaa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## VECTORIZING THE AVERAGE OPERATION\n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / torch.sum(weights, 1, keepdim=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a2bfe58-a6ba-4be7-a521-1ff06e7fa816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7667, 0.5314],\n",
       "         [0.8419, 0.4044],\n",
       "         [0.6768, 0.3140],\n",
       "         [0.6968, 0.4338],\n",
       "         [0.5678, 0.3777],\n",
       "         [0.5052, 0.4810],\n",
       "         [0.4860, 0.5177],\n",
       "         [0.4990, 0.4670]],\n",
       "\n",
       "        [[0.4926, 0.9296],\n",
       "         [0.4727, 0.9372],\n",
       "         [0.4763, 0.8148],\n",
       "         [0.5202, 0.7491],\n",
       "         [0.4714, 0.6881],\n",
       "         [0.4159, 0.7096],\n",
       "         [0.3833, 0.6908],\n",
       "         [0.3484, 0.6924]],\n",
       "\n",
       "        [[0.8070, 0.4398],\n",
       "         [0.8909, 0.5479],\n",
       "         [0.8884, 0.6760],\n",
       "         [0.6851, 0.6276],\n",
       "         [0.6434, 0.6842],\n",
       "         [0.5839, 0.6148],\n",
       "         [0.5452, 0.6664],\n",
       "         [0.5029, 0.7055]],\n",
       "\n",
       "        [[0.9492, 0.9015],\n",
       "         [0.5072, 0.4551],\n",
       "         [0.4965, 0.4310],\n",
       "         [0.4805, 0.5722],\n",
       "         [0.5735, 0.5497],\n",
       "         [0.6203, 0.5761],\n",
       "         [0.5762, 0.4960],\n",
       "         [0.6111, 0.4887]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights is (T, T) and x is (B, T, C)\n",
    "# pytorch recognizes that and creates a batch dimension so that its\n",
    "# (B, T, T) @ (B, T, C)\n",
    "weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9191f491-efcb-41f9-92fe-df12c53e37d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checks if values are equivalent\n",
    "torch.allclose(xbow, weights @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14a27566-3fde-4846-887e-3b30f7dd4dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7667, 0.5314],\n",
       "         [0.8419, 0.4044],\n",
       "         [0.6768, 0.3140],\n",
       "         [0.6968, 0.4338],\n",
       "         [0.5678, 0.3777],\n",
       "         [0.5052, 0.4810],\n",
       "         [0.4860, 0.5177],\n",
       "         [0.4990, 0.4670]],\n",
       "\n",
       "        [[0.4926, 0.9296],\n",
       "         [0.4727, 0.9372],\n",
       "         [0.4763, 0.8148],\n",
       "         [0.5202, 0.7491],\n",
       "         [0.4714, 0.6881],\n",
       "         [0.4159, 0.7096],\n",
       "         [0.3833, 0.6908],\n",
       "         [0.3484, 0.6924]],\n",
       "\n",
       "        [[0.8070, 0.4398],\n",
       "         [0.8909, 0.5479],\n",
       "         [0.8884, 0.6760],\n",
       "         [0.6851, 0.6276],\n",
       "         [0.6434, 0.6842],\n",
       "         [0.5839, 0.6148],\n",
       "         [0.5452, 0.6664],\n",
       "         [0.5029, 0.7055]],\n",
       "\n",
       "        [[0.9492, 0.9015],\n",
       "         [0.5072, 0.4551],\n",
       "         [0.4965, 0.4310],\n",
       "         [0.4805, 0.5722],\n",
       "         [0.5735, 0.5497],\n",
       "         [0.6203, 0.5761],\n",
       "         [0.5762, 0.4960],\n",
       "         [0.6111, 0.4887]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## USING SOFTMAX\n",
    "# we are building intution for how we go about encoding contextual information into each token by the previous tokens only\n",
    "# now instead of just taking the average of the token subsequence (inclusive) to be the current token, we can use softmax to give us a normalized decimal contribution of each previous token to the current token\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "print(tril)\n",
    "# these are set to 0 right now BUT\n",
    "# these weights will be the attention pattern that we learn in the future\n",
    "# this is after the embeddings of all tokens have been mapped to the key query space in the columns and rows respectively and the dot products of these respective columns' and rows' key/query vectors have been computed\n",
    "# each (tr, tc) in the weights matrix is the (W_k @ T_n) @ (W_q @ T_n)\n",
    "# key_r = W_k @ T_n\n",
    "# query_c = W_q @ T_n\n",
    "# now that we understand the weight matrix we will apply masking so that future token information doesnt get encoded into any token\n",
    "# the form the weights matrix is in, in this notebook is the transpose of the form it is in, in the 3b1b video\n",
    "weights = torch.zeros((T, T))\n",
    "# setting the upper triangle of the weights matrix (which can be seen as 0s in tril) to -inf because after applying softmax the -inf's go to 0 and the rest of the values add up to 1 and we have a valid probability distribution\n",
    "weights = torch.masked_fill(weights, tril == 0, float(\"-inf\"))\n",
    "print(weights)\n",
    "# -1 dim means we do it across the last dimension which is the row dimension\n",
    "# we can also just use 1 as the dim to specify the row dimension (for a 2x2 weights matrix like we have here) but -1 is generalizable\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "print(weights)\n",
    "softmaxBowWOW = weights @ x\n",
    "softmaxBowWOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2711134-0dc6-4c23-b224-fc7db352162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 32])\n",
      "tensor([[[-1.1131,  0.5709, -0.1162,  ...,  0.7472,  0.6243, -0.2236],\n",
      "         [-0.9526,  1.1547, -0.2072,  ...,  0.3372,  0.4379, -0.6110],\n",
      "         [-0.6856,  0.3799,  0.0517,  ...,  0.1590,  0.2242,  0.0108],\n",
      "         ...,\n",
      "         [-1.5999,  0.7860, -0.8684,  ...,  1.2739,  1.7156, -0.3900],\n",
      "         [-1.2997,  0.9643, -0.6678,  ...,  0.8460,  1.1088, -0.3689],\n",
      "         [-0.8024,  0.9467, -0.0853,  ...,  0.2087,  0.0361, -0.0566]],\n",
      "\n",
      "        [[ 1.4529,  0.2413,  0.2447,  ...,  0.9274, -2.4062, -0.2953],\n",
      "         [ 0.8658, -0.1639,  0.0378,  ...,  0.5807, -1.5448, -0.1430],\n",
      "         [ 0.4775, -0.6827,  0.0276,  ...,  0.1490, -0.1697,  0.1547],\n",
      "         ...,\n",
      "         [ 1.7115, -0.6649,  0.6615,  ...,  0.7575,  0.4393,  0.5986],\n",
      "         [ 0.0145,  0.2786,  1.2535,  ...,  0.0973, -0.5672,  0.1354],\n",
      "         [ 0.4402,  0.0713,  0.6413,  ...,  0.0179, -0.4803, -0.1015]],\n",
      "\n",
      "        [[ 0.6063,  0.9585, -0.3751,  ..., -1.4635,  0.1501,  0.0207],\n",
      "         [-0.0700,  0.1352,  0.9661,  ...,  0.0933,  0.0219,  0.5383],\n",
      "         [ 0.6065,  0.5700, -0.2994,  ..., -1.1641, -0.0067,  0.0303],\n",
      "         ...,\n",
      "         [ 0.5025,  0.8548,  0.8166,  ..., -1.3489,  0.0704,  0.1075],\n",
      "         [-0.8653,  0.2068, -0.6693,  ...,  1.2554,  0.1256,  0.0476],\n",
      "         [ 0.0483, -0.4853, -1.0282,  ...,  0.5065,  0.1729, -0.2888]],\n",
      "\n",
      "        [[ 1.6554, -0.2188,  0.2475,  ..., -0.2130,  0.2478, -1.0320],\n",
      "         [ 0.7003, -0.6315, -0.0029,  ..., -0.0189,  0.3067, -1.1247],\n",
      "         [ 1.3791, -0.1930,  0.2176,  ..., -0.1154,  0.4637, -0.8670],\n",
      "         ...,\n",
      "         [-0.1274,  0.9812, -0.8226,  ...,  0.6430,  1.1221,  1.0045],\n",
      "         [ 0.2804,  0.1703, -0.0335,  ...,  0.4341,  0.7170, -0.1474],\n",
      "         [-0.3679,  0.8465, -0.3982,  ...,  0.5587,  0.3782,  0.0407]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# IMPLEMENTING A SINGLE HEAD OF ATTENTION - one query and one key\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# SINGLE HEAD\n",
    "# dimensions of key-query space\n",
    "head_size = 16\n",
    "# key and query Linear layers map from the 32 length vector embeddings to the key-query space vectors\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "# here we map the token embeddings to the key-query space\n",
    "K = key(x) # (B, T, head_size)\n",
    "Q = query(x) # (B, T, head_size)\n",
    "# now we need to create the attention pattern matrix which is a T, T matrix for each group of tokens in a batch\n",
    "# tranpose method for K: (B, T, head_size) => (B, head_size, T)\n",
    "# we do this tranpose because currently for any batch for Q we have 4 groups of 8, length 16 (head_size) vectors \n",
    "# the attention pattern is a square matrix and to create that square matrix attention pattern for each element of the batch we need to tranpose K\n",
    "# we need calculate the dot product between pairs of key query vectors for one token\n",
    "# if we do this correctly we should get a scalar value for each key query vector pair for each token for each token\n",
    "# and for that reason we need to tranpose the K matrix in such a way that we get 4 attention patterns (because thats 1 (T, T) matrix for each item in the batch)\n",
    "# the reason we multiply by the square root of head size is because the variance of the weights matrix is very high after the key query dot product even if the key and query matrices' varainces are low\n",
    "# and if we run softmax on the rows with high variance, softmax will converge to one hot vectors\n",
    "# this is because say for example if we have large magnitude negative values and large magnitude positive values, by themselves they aren't too far apart, but softmax enhances that disparity sharpens it and the large magnitude positive values will converege on one while low values will converge on 0\n",
    "# for this reason we divide by sqrt(head_size) for normalization to control this variance\n",
    "# variance drops much lower after applying this term roughly to the same as the original key and query matrices\n",
    "weights = Q @ K.transpose(-2, -1) * (head_size ** -0.5) # (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# weights = torch.zeros((T, T))\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "V = value(x)\n",
    "out = weights @ V # (B, T, head_size) which is (4, 8, 16) here\n",
    "\n",
    "'''\n",
    "out = weights @ x\n",
    "print(out.shape)\n",
    "print(out)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e782da79-e924-4c64-bf94-83b0d2243f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdbe43-944a-4625-b649-b643a3ad2dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1adaa-cf4b-4524-9105-6d9d8bda0976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
